{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56a83565",
   "metadata": {},
   "source": [
    "#### Pyspark Handling Missing Values\n",
    "\n",
    "- Dropping Columns\n",
    "- Dropping Rows\n",
    "- Various Parameter in Dropping functionalities\n",
    "- Handling Missing Values by Mean, Median and Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fee58e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcae542f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   name| age|experience|salary|\n",
      "+-------+----+----------+------+\n",
      "|Ajinkya|  33|        10| 30000|\n",
      "| Hitesh|  30|         8| 25000|\n",
      "|    Jay|  29|         4| 20000|\n",
      "|  Anish|  24|         3| 20000|\n",
      "| Nikhil|  21|         1| 15000|\n",
      "|  Pavan|  23|         2| 18000|\n",
      "|  Rohit|null|      null| 38000|\n",
      "|   null|  34|        10| 40000|\n",
      "|   null|  36|      null|  null|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv('test2.csv', header=True, inferSchema=True)\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ffdc61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------+------+\n",
      "| age|experince|salary|\n",
      "+----+---------+------+\n",
      "|  33|       10| 30000|\n",
      "|  30|        8| 25000|\n",
      "|  29|        4| 20000|\n",
      "|  24|        3| 20000|\n",
      "|  21|        1| 15000|\n",
      "|  23|        2| 18000|\n",
      "|null|     null| 38000|\n",
      "|  34|       10| 40000|\n",
      "|  36|     null|  null|\n",
      "+----+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## drop the columns\n",
    "df_pyspark.drop('name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c459ca76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0------------\n",
      " name      | Ajinkya \n",
      " age       | 33      \n",
      " experince | 10      \n",
      " salary    | 30000   \n",
      "-RECORD 1------------\n",
      " name      | Hitesh  \n",
      " age       | 30      \n",
      " experince | 8       \n",
      " salary    | 25000   \n",
      "-RECORD 2------------\n",
      " name      |  Jay    \n",
      " age       | 29      \n",
      " experince | 4       \n",
      " salary    | 20000   \n",
      "-RECORD 3------------\n",
      " name      |  Anish  \n",
      " age       | 24      \n",
      " experince | 3       \n",
      " salary    | 20000   \n",
      "-RECORD 4------------\n",
      " name      |  Nikhil \n",
      " age       | 21      \n",
      " experince | 1       \n",
      " salary    | 15000   \n",
      "-RECORD 5------------\n",
      " name      |  Pavan  \n",
      " age       | 23      \n",
      " experince | 2       \n",
      " salary    | 18000   \n",
      "-RECORD 6------------\n",
      " name      |  Rohit  \n",
      " age       | null    \n",
      " experince | null    \n",
      " salary    | 38000   \n",
      "-RECORD 7------------\n",
      " name      | null    \n",
      " age       | 34      \n",
      " experince | 10      \n",
      " salary    | 40000   \n",
      "-RECORD 8------------\n",
      " name      | null    \n",
      " age       | 36      \n",
      " experince | null    \n",
      " salary    | null    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show(vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c095b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+---------+------+\n",
      "|   name| age|experince|salary|\n",
      "+-------+----+---------+------+\n",
      "|Ajinkya|  33|       10| 30000|\n",
      "| Hitesh|  30|        8| 25000|\n",
      "|    Jay|  29|        4| 20000|\n",
      "|  Anish|  24|        3| 20000|\n",
      "| Nikhil|  21|        1| 15000|\n",
      "|  Pavan|  23|        2| 18000|\n",
      "|  Rohit|null|     null| 38000|\n",
      "|   null|  34|       10| 40000|\n",
      "|   null|  36|     null|  null|\n",
      "+-------+----+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "972f9234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---------+------+\n",
      "|   name|age|experince|salary|\n",
      "+-------+---+---------+------+\n",
      "|Ajinkya| 33|       10| 30000|\n",
      "| Hitesh| 30|        8| 25000|\n",
      "|    Jay| 29|        4| 20000|\n",
      "|  Anish| 24|        3| 20000|\n",
      "| Nikhil| 21|        1| 15000|\n",
      "|  Pavan| 23|        2| 18000|\n",
      "+-------+---+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70f79c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---------+------+\n",
      "|   name|age|experince|salary|\n",
      "+-------+---+---------+------+\n",
      "|Ajinkya| 33|       10| 30000|\n",
      "| Hitesh| 30|        8| 25000|\n",
      "|    Jay| 29|        4| 20000|\n",
      "|  Anish| 24|        3| 20000|\n",
      "| Nikhil| 21|        1| 15000|\n",
      "|  Pavan| 23|        2| 18000|\n",
      "+-------+---+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### any == how\n",
    "df_pyspark.na.drop(how='any').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab734865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+---------+------+\n",
      "|   name| age|experince|salary|\n",
      "+-------+----+---------+------+\n",
      "|Ajinkya|  33|       10| 30000|\n",
      "| Hitesh|  30|        8| 25000|\n",
      "|    Jay|  29|        4| 20000|\n",
      "|  Anish|  24|        3| 20000|\n",
      "| Nikhil|  21|        1| 15000|\n",
      "|  Pavan|  23|        2| 18000|\n",
      "|  Rohit|null|     null| 38000|\n",
      "|   null|  34|       10| 40000|\n",
      "|   null|  36|     null|  null|\n",
      "+-------+----+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### how == all\n",
    "df_pyspark.na.drop(how='all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccbd7863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+---------+------+\n",
      "|   name| age|experince|salary|\n",
      "+-------+----+---------+------+\n",
      "|Ajinkya|  33|       10| 30000|\n",
      "| Hitesh|  30|        8| 25000|\n",
      "|    Jay|  29|        4| 20000|\n",
      "|  Anish|  24|        3| 20000|\n",
      "| Nikhil|  21|        1| 15000|\n",
      "|  Pavan|  23|        2| 18000|\n",
      "|  Rohit|null|     null| 38000|\n",
      "|   null|  34|       10| 40000|\n",
      "+-------+----+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### threshold   thresh=2 means at least 2 \"NON NULL VALUES\" should be present in a row\n",
    "\n",
    "df_pyspark.na.drop(how='any', thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6c185da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   name|age|experience|salary|\n",
      "+-------+---+----------+------+\n",
      "|Ajinkya| 33|        10| 30000|\n",
      "| Hitesh| 30|         8| 25000|\n",
      "|    Jay| 29|         4| 20000|\n",
      "|  Anish| 24|         3| 20000|\n",
      "| Nikhil| 21|         1| 15000|\n",
      "|  Pavan| 23|         2| 18000|\n",
      "|   null| 34|        10| 40000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### subset \n",
    "### if there are null values in a row of optional list of column names to consider.\n",
    "### that row will be omitted \n",
    "\n",
    "df_pyspark.na.drop(how='any', subset=['experience']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "817eb022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+--------------+--------------+\n",
      "|          name|           age|    experience|        salary|\n",
      "+--------------+--------------+--------------+--------------+\n",
      "|       Ajinkya|            33|            10|         30000|\n",
      "|        Hitesh|            30|             8|         25000|\n",
      "|           Jay|            29|             4|         20000|\n",
      "|         Anish|            24|             3|         20000|\n",
      "|        Nikhil|            21|             1|         15000|\n",
      "|         Pavan|            23|             2|         18000|\n",
      "|         Rohit|Missing Values|Missing Values|         38000|\n",
      "|Missing Values|            34|            10|         40000|\n",
      "|Missing Values|            36|Missing Values|Missing Values|\n",
      "+--------------+--------------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Filling the Missing Values\n",
    "df_pyspark.na.fill('Missing Values').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eb100cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+----------+------+\n",
      "| name|  age|experience|salary|\n",
      "+-----+-----+----------+------+\n",
      "|Aj...|   33|        10| 30000|\n",
      "|Hi...|   30|         8| 25000|\n",
      "|  Jay|   29|         4| 20000|\n",
      "| A...|   24|         3| 20000|\n",
      "| N...|   21|         1| 15000|\n",
      "| P...|   23|         2| 18000|\n",
      "| R...|Mi...|     Mi...| 38000|\n",
      "| null|   34|        10| 40000|\n",
      "| null|   36|     Mi...|  null|\n",
      "+-----+-----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.fill(value='Missing Values', subset=['age', 'experience']).show(truncate=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87dad13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   name| age|experience|salary|\n",
      "+-------+----+----------+------+\n",
      "|Ajinkya|  33|        10| 30000|\n",
      "| Hitesh|  30|         8| 25000|\n",
      "|    Jay|  29|         4| 20000|\n",
      "|  Anish|  24|         3| 20000|\n",
      "| Nikhil|  21|         1| 15000|\n",
      "|  Pavan|  23|         2| 18000|\n",
      "|  Rohit|null|      null| 38000|\n",
      "|   null|  34|        10| 40000|\n",
      "|   null|  36|      null|  null|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5828752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols=['age', 'experience', 'salary'],\n",
    "    outputCols=[\"{}_imputed\".format(c) for c in ['age', 'experience', 'salary']]\n",
    ").setStrategy('mean')                      \n",
    "## you can change it to 'Mean', 'Median', 'Mode'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6722a31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "|   name| age|experience|salary|age_imputed|experience_imputed|salary_imputed|\n",
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "|Ajinkya|  33|        10| 30000|         33|                10|         30000|\n",
      "| Hitesh|  30|         8| 25000|         30|                 8|         25000|\n",
      "|    Jay|  29|         4| 20000|         29|                 4|         20000|\n",
      "|  Anish|  24|         3| 20000|         24|                 3|         20000|\n",
      "| Nikhil|  21|         1| 15000|         21|                 1|         15000|\n",
      "|  Pavan|  23|         2| 18000|         23|                 2|         18000|\n",
      "|  Rohit|null|      null| 38000|         28|                 5|         38000|\n",
      "|   null|  34|        10| 40000|         34|                10|         40000|\n",
      "|   null|  36|      null|  null|         36|                 5|         25750|\n",
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df_pyspark).transform(df_pyspark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88e2c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8368aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3d784d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
